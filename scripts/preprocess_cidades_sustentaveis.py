"""
Este script realiza o pr√©-processamento
da fonte de dados 'Cidades Sustent√°veis',
produzindo um arquivo CSV padronizado pronto para ingest√£o via dbt.

Etapas realizadas:
- Leitura e renomea√ß√£o de colunas relevantes
- Convers√£o segura de campo 'valor' para float
- Limpeza de quebras de linha e tipos
- Adi√ß√£o de data de processamento
- (Opcional) Recategoriza√ß√£o por LLM local por indicador_id
- Upload para bucket GCS (bruto + processado)

üìÅ O resultado limpo √© salvo localmente em:
    dados/cidades-sustentaveis/indicadores_padronizados.csv

üß† Caso a recategoriza√ß√£o por IA esteja habilitada:
    ‚Üí Um cache incremental por indicador_id ser√° mantido em:
      dados/cidades-sustentaveis/eixos_llm.json
    ‚Üí Apenas novos indicadores n√£o presentes nesse cache
      ser√£o enviados ao modelo LLM local para classifica√ß√£o

PR√ìXIMOS PASSOS (fora do escopo deste script):

‚Üí No dbt:
  - Cria√ß√£o do modelo stg_indicadores__cidades_sustentaveis
  - Aplica√ß√£o de CASTs, filtros, testes de qualidade
    (not null, accepted_values, etc.)
  - Exclus√£o de registros inv√°lidos ou incompletos
  - Prepara√ß√£o do modelo dim_indicadores com enriquecimentos

‚Üí Recategoriza√ß√£o dos eixos:
  - O campo 'eixo' √© mantido como informado pela fonte
  - A categoriza√ß√£o final ser√° feita por:
      ‚Ä¢ IA local durante o pr√©-processamento (eixo_ia)
      ‚Ä¢ ou join com tabela auxiliar (indicador_id ‚Üí eixo_padrao)
  - A normaliza√ß√£o permitir√° alinhar com o enum Eixos (SAUDE, EDUCACAO, etc.)
"""


import pandas as pd
from google.cloud import storage
import os
from datetime import datetime, timezone
import json
from pathlib import Path
from scripts.meu_llm import classificar_eixo, check_server


# === CONFIGURA√á√ïES ===
CAMINHO_BRUTO = "dados/cidades-sustentaveis/indicadores.csv"
CAMINHO_LIMPO = "dados/cidades-sustentaveis/indicadores_padronizados.csv"
BUCKET_NAME = "observatudo-infra-www-data"
DESTINO_BRUTO = "indicadores/brutos/cidades-sustentaveis/indicadores.csv"
DESTINO_PROCESSADO = (
    "indicadores/processados/cidades-sustentaveis/indicadores.csv"
)

# === ETAPA 1: Leitura do CSV bruto ===
df = pd.read_csv(CAMINHO_BRUTO)

# === ETAPA 2: Renomear colunas relevantes ===
colunas_renomeadas = {
    "C√≥digo IBGE": "codigo_ibge",
    "Nome da cidade": "nome_cidade",
    "UF": "uf",
    "Estado Nome": "estado_nome",
    "Eixo": "eixo",
    "ID Indicador": "indicador_id",
    "Nome do indicador": "nome",
    "Formula do indicador": "formula",
    "Meta ODS": "meta_ods",
    "N√∫mero ODS": "numero_ods",
    "Nome do ODS": "nome_ods",
    "Descri√ß√£o do indicador": "descricao",
    "Ano de Preenchimento": "ano",
    "Valor": "valor",
    "Justificativa": "justificativa"
}

df = df.rename(columns=colunas_renomeadas)
df = df[list(colunas_renomeadas.values())]

"""
=== ETAPA 2.5: Recategoriza√ß√£o com LLM local ===

Esta etapa utiliza um modelo LLM
(ex: rodando localmente via Ollama, LM Studio, etc.)
para classificar automaticamente cada `indicador_id` em um eixo tem√°tico.

Fluxo:
1. Um cache incremental √© salvo em: dados/cidades-sustentaveis/eixos_llm.json
2. Se o indicador j√° foi classificado, reutiliza o valor salvo
3. Apenas novos indicadores s√£o enviados ao modelo via HTTP (Ollama)
4. O resultado √© salvo na coluna `eixo_ia` e persistido no cache

üõë Se o servidor Ollama n√£o estiver acess√≠vel ou o modelo n√£o carregado,
    a etapa de categoriza√ß√£o √© automaticamente ignorada
    (o script segue normalmente).
"""

CAMINHO_MAPA_EIXOS = "dados/cidades-sustentaveis/eixos_llm.json"

if check_server():
    # Carregar mapeamento salvo anteriormente
    if Path(CAMINHO_MAPA_EIXOS).exists():
        with open(CAMINHO_MAPA_EIXOS, encoding="utf-8") as f:
            mapeamento_eixos = json.load(f)
    else:
        mapeamento_eixos = {}

    # Agrupar por indicador_id e classificar apenas os novos
    agrupado = df.groupby("indicador_id").first()

    for cod, row in agrupado.iterrows():
        if cod not in mapeamento_eixos:
            texto = f"{row['nome']} - {row.get('descricao', '')}"
            eixo = classificar_eixo(texto)
            mapeamento_eixos[cod] = eixo

    # Aplicar ao DataFrame principal
    df["eixo_ia"] = df["indicador_id"].map(mapeamento_eixos)

    # Salvar o mapeamento atualizado
    os.makedirs(os.path.dirname(CAMINHO_MAPA_EIXOS), exist_ok=True)
    with open(CAMINHO_MAPA_EIXOS, "w", encoding="utf-8") as f:
        json.dump(mapeamento_eixos, f, ensure_ascii=False, indent=2)

else:
    print("‚ö†Ô∏è Recategoriza√ß√£o ignorada: servidor Ollama n√£o acess√≠vel.")

# === ETAPA 3: Convers√µes seguras ===

# ‚Üí valor: texto com v√≠rgula ‚Üí float (ou NaN se n√£o for n√∫mero)
df["valor_original"] = df["valor"]  # backup
df["valor"] = pd.to_numeric(
    df["valor"]
    .astype(str)
    .str.replace(".", "", regex=False)
    .str.replace(",", ".", regex=False),
    errors="coerce"
)

# ‚Üí justificativa: remover quebras de linha
df["justificativa"] = df["justificativa"].fillna("").str.replace("\n", " ")

# ‚Üí ano: transformar em inteiro seguro
df["ano"] = pd.to_numeric(df["ano"], errors="coerce").astype("Int64")

# ‚Üí data de processamento
df["data_processamento"] = datetime.now(timezone.utc)

# === ETAPA 4: Estat√≠sticas de qualidade ===
total = len(df)
com_valor = df["valor"].notna().sum()
sem_valor = df["valor"].isna().sum()

print("üìä Estat√≠sticas do pr√©-processamento:")
print(f" - Total de registros: {total}")
print(f" - Registros com valor num√©rico: {com_valor}")
print(f" - Registros ignorados por valor inv√°lido: {sem_valor}")

# === ETAPA 5: Salvar CSV limpo localmente ===
os.makedirs(os.path.dirname(CAMINHO_LIMPO), exist_ok=True)
df.to_csv(CAMINHO_LIMPO, index=False)

# === ETAPA 6: Upload dos arquivos para o bucket ===
client = storage.Client()
bucket = client.bucket(BUCKET_NAME)

# Upload do bruto
blob_bruto = bucket.blob(DESTINO_BRUTO)
blob_bruto.upload_from_filename(CAMINHO_BRUTO)

# Upload do processado
blob_proc = bucket.blob(DESTINO_PROCESSADO)
blob_proc.upload_from_filename(CAMINHO_LIMPO)

print("‚úÖ Upload conclu√≠do com sucesso:")
print(f" - Bruto: {DESTINO_BRUTO}")
print(f" - Processado: {DESTINO_PROCESSADO}")
