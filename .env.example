# URL do seu servidor Ollama local
OLLAMA_BASE_URL=http://localhost:11434

# Nome do modelo LLM carregado no Ollama
OLLAMA_MODEL=qwen2.5-coder:0.5b